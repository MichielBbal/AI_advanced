{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image embeddings: Cats and Dogs\n",
    "\n",
    "Can the AI identify and differentiate between cats and dogs with only a few examples?\n",
    "\n",
    "Note that this notebook requires umap and umap.plot; you can install both via `pip3 install umap-learn umap-learn[plot]`\n",
    "\n",
    "This notebook also requires installing `datasets`.\n",
    "\n",
    "Sources:\n",
    "- https://pypi.org/project/imgbeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imgbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mUmap\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_rng\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#import umap.plot\u001b[39;00m\n\u001b[1;32m     11\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "from imgbeddings import imgbeddings\n",
    "from PIL import Image\n",
    "import logging\n",
    "import numpy as np\n",
    "import datasets\n",
    "from numpy.random import default_rng\n",
    "import umap\n",
    "#import umap.plot\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell downloads the famous [Cats vs. Dogs dataset](https://huggingface.co/datasets/cats_vs_dogs) which includes about 23 thousand images; the download is about 800MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.load_dataset(\"cats_vs_dogs\", split=\"train\", ignore_verifications=True)\n",
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 1000 each of random cats (label `0`) and random dogs (label `1`) for a perfectly balanced dataset, as all datasets should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "rng = default_rng(42)\n",
    "cat_idx = rng.choice(np.where(np.array(df[\"labels\"]) == 0)[0], n, replace=False)\n",
    "dog_idx = rng.choice(np.where(np.array(df[\"labels\"]) == 1)[0], n, replace=False)\n",
    "idx = np.hstack((cat_idx, dog_idx))\n",
    "rng.shuffle(idx)\n",
    "\n",
    "idx[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_source = [df[int(x)][\"image_file_path\"] for x in idx]\n",
    "images = [df[int(x)][\"image\"] for x in idx]\n",
    "labels = [df[int(x)][\"labels\"] for x in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the images we selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some of the loaded images in a grid:\n",
    "# https://stackoverflow.com/a/65583584\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = 8\n",
    "image_grid([x.resize((64,64)) for x in images[0:(n_rows*n_cols)]], n_rows, n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[0:(n_rows*n_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the images can be converted to embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibed = imgbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = ibed.to_embeddings(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP unsupervised clustering\n",
    "\n",
    "umap is a tool that can cluster embeddings (better/more efficient than the popular tSNE) and then visualize the results.\n",
    "\n",
    "Using cosine similarity works best here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap_catsdogs = umap.UMAP(\n",
    "    n_neighbors=10, n_components=2, metric=\"cosine\", random_state=42\n",
    ").fit(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap.plot.points(umap_catsdogs, labels=np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two groups are noticeably distinct, although there are several outliers in both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cat/Dog Classifier with a simple Logistic Regression\n",
    "\n",
    "Here's a simple `scikit-learn` binary classifier using the generated embeddings to determine whether an image is a cat or a dog, which is just as simple as any other generic online tutorial.\n",
    "\n",
    "However, `max_iter` is increased due to the nature of providing raw embeddings vs. tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classifier = LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(embeddings, labels, test_size=test_size, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected. For comparison, the [Kaggle Competiton](https://www.kaggle.com/competitions/dogs-vs-cats/leaderboard) for this dataset had a best score of 0.989, although with a different/larger validation set, and without the power of modern AI frameworks.\n",
    "\n",
    "Let's look at misclassified images by finding the indices of where the predictions were incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(x_test)\n",
    "idx_mismatch = np.where(y_test != predicted)\n",
    "idx_mismatch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map those indicies back to the original 2000 image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/51352806\n",
    "misclass_idx = np.where((embeddings[:, None] == x_test[idx_mismatch]).all(-1).any(-1))\n",
    "misclass_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 1\n",
    "n_cols = len(list(misclass_idx[0]))\n",
    "image_grid([images[x].resize((128,128)) for x in list(misclass_idx[0])], n_rows, n_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first image is interesting: the cage bars \"mask\" the image of the dog which explain how the model may get confused.\n",
    "\n",
    "The second image however is shennanigans: putting both a dog and a cat in the same image is cheating IMO."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
