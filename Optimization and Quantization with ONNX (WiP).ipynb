{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccbd4192",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation, optimization and Quantization\n",
    "source: https://www.youtube.com/watch?v=_AKFDOnrZz8\n",
    "\n",
    "credits: Julien Simon, Huggingface, source: https://gitlab.com/juliensimon/huggingface-demos/-/blob/main/optimum/onnx/optimize_onnx.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a4b44",
   "metadata": {},
   "source": [
    "### Huggingface's evaluation model\n",
    "\n",
    "ðŸ¤— Evaluate's main methods are:\n",
    "\n",
    "- evaluate.list_evaluation_modules() to list the available metrics, comparisons and measurements\n",
    "- evaluate.load(module_name, **kwargs) to instantiate an evaluation module\n",
    "- results = module.compute(*kwargs) to compute the result of an evaluation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241874f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70dd3038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: dill in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (0.17.3)\n",
      "Requirement already satisfied: packaging in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80d6f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum\n",
      "  Downloading optimum-1.17.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: coloredlogs in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: sympy in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from optimum) (1.11.1)\n",
      "Requirement already satisfied: transformers>=4.26.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (4.35.1)\n",
      "Requirement already satisfied: torch>=1.11 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from optimum) (2.0.0)\n",
      "Requirement already satisfied: packaging in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from optimum) (23.2)\n",
      "Requirement already satisfied: numpy in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from optimum) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from optimum) (0.17.3)\n",
      "Requirement already satisfied: datasets in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from optimum) (2.14.5)\n",
      "Requirement already satisfied: filelock in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2023.6.0)\n",
      "Requirement already satisfied: requests in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.4.0)\n",
      "Requirement already satisfied: networkx in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum) (0.3.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\n",
      "Requirement already satisfied: protobuf in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (3.20.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets->optimum) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets->optimum) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets->optimum) (2.0.1)\n",
      "Requirement already satisfied: xxhash in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets->optimum) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets->optimum) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from datasets->optimum) (3.8.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->optimum) (1.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from pandas->datasets->optimum) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
      "Downloading optimum-1.17.1-py3-none-any.whl (407 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m407.1/407.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: optimum\n",
      "Successfully installed optimum-1.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2c354",
   "metadata": {},
   "source": [
    "# Part 1: Julien Simon tutorial on youtube > 1 old & outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59daee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 09:26:27.301918: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import evaluate\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "febc0b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610dcc47678149ba9e085b6934f29b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfd17c981bb42eeaea8f8dbcbad755c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/736 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279ce7037224437cb6d47475c668e1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1712eb98b6f349e7922e387477894945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/10.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55131dbc8be4646b8a3ea94fcabe1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de183d1d63924a45acc002d6a9edc8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90f1bada75c452fa3a0534243680212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776bf58b67df493a9ea4a88ff973ae02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'text'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#settings\n",
    "task_type = \"text-classification\"\n",
    "\n",
    "model_id = \"juliensimon/distilbert-amazon-shoe-reviews\"\n",
    "\n",
    "dataset_id = \"juliensimon/amazon-shoe-reviews\"\n",
    "label_column = \"labels\"\n",
    "label_mapping = {\n",
    "    \"LABEL_0\": 0,\n",
    "    \"LABEL_1\": 1,\n",
    "    \"LABEL_2\": 2,\n",
    "    \"LABEL_3\": 3,\n",
    "    \"LABEL_4\": 4,\n",
    "}\n",
    "data = datasets.load_dataset(dataset_id, split=\"test\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a23a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5399dbe4d8034b338abccdf4f90d35e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Original model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1630340251bd4a65947d6032219e9dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/845 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0205c140bc4d7fabd62822950986a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986859eeb8a54499a079f2fa87c2400f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dc16ebff024d4c9454dea1f2d7a40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1587b2ddf04e3fb82abb8ebd5c7de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d0fc256eb147598a61c1ce02f079db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5778, 'total_time_in_seconds': 375.2978071240068, 'samples_per_second': 26.645506075914202, 'latency_in_seconds': 0.03752978071240068}\n"
     ]
    }
   ],
   "source": [
    "# evaluation of the original model\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "evaluator = evaluate.evaluator(task_type)\n",
    "\n",
    "\n",
    "def evaluate_pipeline(pipeline):\n",
    "    results = evaluator.compute(\n",
    "        model_or_pipeline=pipeline,\n",
    "        data=data,\n",
    "        metric=metric,\n",
    "        label_column=label_column,\n",
    "        label_mapping=label_mapping,\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"*** Original model\")\n",
    "classifier = transformers.pipeline(task_type, model_id)\n",
    "results = evaluate_pipeline(classifier)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0afc9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import optimum \n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from optimum.pipelines import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b67810",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find any ONNX model file in juliensimon/distilbert-amazon-shoe-reviews",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjuliensimon/distilbert-amazon-shoe-reviews\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mORTModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#model.save_pretrained(\"./model_onnx\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#tokenizer.save_pretrained(\"./model_onnx\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#classifier_onnx = pipeline(task_type, model=model, tokenizer=tokenizer)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#results = evaluate_pipeline(classifier_onnx)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** ONNX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/optimum/onnxruntime/modeling_ort.py:662\u001b[0m, in \u001b[0;36mORTModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, provider, session_options, provider_options, use_io_binding, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(FROM_PRETRAINED_START_DOCSTRING)\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    630\u001b[0m ):\n\u001b[1;32m    631\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    provider (`str`, defaults to `\"CPUExecutionProvider\"`):\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03m        ONNX Runtime provider to use for loading the model. See https://onnxruntime.ai/docs/execution-providers/ for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;124;03m        `ORTModel`: The loaded ORTModel model.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_io_binding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_io_binding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/optimum/modeling_base.py:399\u001b[0m, in \u001b[0;36mOptimizedModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    397\u001b[0m from_pretrained_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_transformers \u001b[38;5;28;01mif\u001b[39;00m export \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_pretrained_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/optimum/onnxruntime/modeling_ort.py:478\u001b[0m, in \u001b[0;36mORTModel._from_pretrained\u001b[0;34m(cls, model_id, config, use_auth_token, revision, force_download, cache_dir, file_name, subfolder, local_files_only, provider, session_options, provider_options, use_io_binding, model_save_dir, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m     onnx_files \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m repo_files \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mmatch(pattern)]\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(onnx_files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find any ONNX model file in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(onnx_files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many ONNX model files were found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, specify which one to load by using the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Could not find any ONNX model file in juliensimon/distilbert-amazon-shoe-reviews"
     ]
    }
   ],
   "source": [
    "model_id = \"juliensimon/distilbert-amazon-shoe-reviews\"\n",
    "model = ORTModelForSequenceClassification.from_pretrained(model_id)\n",
    "#tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "#model.save_pretrained(\"./model_onnx\")\n",
    "#tokenizer.save_pretrained(\"./model_onnx\")\n",
    "#classifier_onnx = pipeline(task_type, model=model, tokenizer=tokenizer)\n",
    "#results = evaluate_pipeline(classifier_onnx)\n",
    "print(\"*** ONNX\")\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a95c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** ONNX optimizer\")\n",
    "\n",
    "from optimum.onnxruntime import ORTOptimizer\n",
    "from optimum.onnxruntime.configuration import OptimizationConfig\n",
    "\n",
    "optimizer = ORTOptimizer.from_pretrained(model)\n",
    "optimizer.optimize(\n",
    "    OptimizationConfig(\n",
    "        optimization_level=99, # 1, 2 or 99\n",
    "    ),\n",
    "    save_dir=\"./model_onnx\",\n",
    ")\n",
    "model_optimized = ORTModelForSequenceClassification.from_pretrained(\n",
    "    \"./model_onnx\", file_name=\"model_optimized.onnx\"\n",
    ")\n",
    "classifier_optimized = pipeline(task_type, model=model_optimized, tokenizer=tokenizer)\n",
    "results = evaluate_pipeline(classifier_optimized)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** ONNX quantizer\")\n",
    "\n",
    "from optimum.onnxruntime import ORTQuantizer\n",
    "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
    "\n",
    "quantizer = ORTQuantizer.from_pretrained(model)\n",
    "qconfig = AutoQuantizationConfig.avx512_vnni(is_static=False, per_channel=True)\n",
    "quantizer.quantize(save_dir=\"./model_onnx\", quantization_config=qconfig)\n",
    "model_quantized = ORTModelForSequenceClassification.from_pretrained(\n",
    "    \"./model_onnx\", file_name=\"model_quantized.onnx\"\n",
    ")\n",
    "classifier_quantized = pipeline(task_type, model=model_quantized, tokenizer=tokenizer)\n",
    "results = evaluate_pipeline(classifier_quantized)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc8297",
   "metadata": {},
   "source": [
    "# Part 2: Huggingface tutorial (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08364d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6a72a94713406d8a454efcd82943ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export the model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a0c08949b74c00aa41dce1f13d2321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb488d58a143ccac8c5a76ab48af40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce8e5009c544273995d964ca8e6c2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from optimum.pipelines import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", accelerator=\"ort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c74149f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998763799667358}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I like you. I love you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54c912e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export the model.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.0.0\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9041661620140076, 'start': 11, 'end': 18, 'answer': 'Philipp'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.pipelines import pipeline\n",
    "\n",
    "onnx_qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", accelerator=\"ort\")\n",
    "question = \"What's my name?\"\n",
    "context = \"My name is Philipp and I live in Nuremberg.\"\n",
    "\n",
    "pred = onnx_qa(question=question, context=context)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22bf2318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export the model.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.0.0\n",
      "/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dynamic quantizer: QOperator (mode: IntegerOps, schema: u8/s8, channel-wise: True)\n",
      "Quantizing model...\n",
      "Saving quantized model at: distilbert_quantized (external data format: False)\n",
      "Configuration saved in distilbert_quantized/ort_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.5954363346099854}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import (\n",
    "    AutoQuantizationConfig,\n",
    "    ORTModelForSequenceClassification,\n",
    "    ORTQuantizer\n",
    ")\n",
    "from optimum.pipelines import pipeline\n",
    "\n",
    "# Load the tokenizer and export the model to the ONNX format\n",
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "save_dir = \"distilbert_quantized\"\n",
    "\n",
    "model = ORTModelForSequenceClassification.from_pretrained(model_id, export=True)\n",
    "\n",
    "# Load the quantization configuration detailing the quantization we wish to apply\n",
    "qconfig = AutoQuantizationConfig.avx512_vnni(is_static=False, per_channel=True)\n",
    "quantizer = ORTQuantizer.from_pretrained(model)\n",
    "\n",
    "# Apply dynamic quantization and save the resulting model\n",
    "quantizer.quantize(save_dir=save_dir, quantization_config=qconfig)\n",
    "# Load the quantized model from a local repository\n",
    "model = ORTModelForSequenceClassification.from_pretrained(save_dir)\n",
    "\n",
    "# Create the transformers pipeline\n",
    "onnx_clx = pipeline(\"text-classification\", model=model, accelerator=\"ort\")\n",
    "text = \"I like the new ORT pipeline\"\n",
    "pred = onnx_clx(text)\n",
    "print(pred)\n",
    "# [{'label': 'POSITIVE', 'score': 0.9974810481071472}]\n",
    "\n",
    "# Save and push the model to the hub (in practice save_dir could be used here instead)\n",
    "#model.save_pretrained(\"new_path_for_directory\")\n",
    "#model.push_to_hub(\"new_path_for_directory\", repository_id=\"my-onnx-repo\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba38c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
