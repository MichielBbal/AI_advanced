{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac78b89",
   "metadata": {},
   "source": [
    "# Gradio front-end for ML models\n",
    "\n",
    "\n",
    "### Sources\n",
    "\n",
    "### Contents\n",
    "1. Install packages\n",
    "2. My first gradio\n",
    "3. More on the tutorial\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bababbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Using cached gradio-3.32.0-py3-none-any.whl (19.9 MB)\n",
      "Requirement already satisfied: pillow in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: numpy in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: httpx in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (0.23.3)\n",
      "Collecting aiofiles\n",
      "  Using cached aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: markupsafe in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: aiohttp in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: pyyaml in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (6.0)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (3.7.0)\n",
      "Collecting gradio-client>=0.2.4\n",
      "  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websockets>=10.0 in /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages (from gradio) (11.0.1)\n",
      "Collecting ffmpy\n",
      "  Using cached ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting orjson\n",
      "  Using cached orjson-3.8.12.tar.gz (669 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Cargo, the Rust package manager, is not installed or is not on PATH.\n",
      "  \u001b[31m   \u001b[0m This package requires Rust and Cargo to compile extensions. Install it through\n",
      "  \u001b[31m   \u001b[0m the system's package manager or via https://rustup.rs/\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Checking for Rust toolchain....\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60982b2b",
   "metadata": {},
   "source": [
    "## 1. My first front end using Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d58ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40b1df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/gradio/routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1435, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1107, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/cj/qtbz9fvd3svc0x28yv2756mh0000gn/T/ipykernel_26902/2989503291.py\", line 22, in run_model\n",
      "    answer = generate_response(question)\n",
      "  File \"/var/folders/cj/qtbz9fvd3svc0x28yv2756mh0000gn/T/ipykernel_26902/2989503291.py\", line 10, in generate_response\n",
      "    response = openai.Completion.create(\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/openai/api_resources/completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/openai/api_requestor.py\", line 230, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/openai/api_requestor.py\", line 624, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/michielbontenbal/anaconda3/lib/python3.10/site-packages/openai/api_requestor.py\", line 687, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.AuthenticationError: Incorrect API key provided: sk-mhDB8***************************************0BtZ. You can find your API key at https://platform.openai.com/account/api-keys.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "import config # my config file contains my api-key\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = config.openai_key\n",
    "\n",
    "# Define the function to generate model responses\n",
    "def generate_response(input_text):\n",
    "    response = openai.Completion.create(\n",
    "        engine='davinci',  # Replace with your preferred engine\n",
    "        prompt=input_text,\n",
    "        max_tokens=100,  # Adjust the max tokens as per your requirements\n",
    "        n=1,  # Number of responses to generate\n",
    "        stop=None,\n",
    "        temperature=0.7  # Adjust the temperature to control the response randomness\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Create the Gradio interface\n",
    "def run_model(question):\n",
    "    answer = generate_response(question)\n",
    "    return answer\n",
    "\n",
    "iface = gr.Interface(fn=run_model, inputs=\"text\", outputs=\"text\", title=\"Large Language Model\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c923ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m gr\u001b[38;5;241m.\u001b[39mInterface(fn\u001b[38;5;241m=\u001b[39m\u001b[43mpredict\u001b[49m,\n\u001b[1;32m      4\u001b[0m              inputs\u001b[38;5;241m=\u001b[39mgr\u001b[38;5;241m.\u001b[39mImage(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpil\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m              outputs\u001b[38;5;241m=\u001b[39mgr\u001b[38;5;241m.\u001b[39mLabel(num_top_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      6\u001b[0m              examples\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlion.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheetah.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mlaunch()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(fn=predict,\n",
    "             inputs=gr.Image(type=\"pil\"),\n",
    "             outputs=gr.Label(num_top_classes=3),\n",
    "             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d96f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
